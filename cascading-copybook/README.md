## Scalable Mainframe Data Processing Using Cascading

Welcome to the tutorial on Scalable Mainframe Data Processing Using Cascading. This tutorial contains source code 
and instructions on how to use Cascading to process data generated by Mainframe computers. We will show you how you 
can use [Legstar](http://www.legsem.com/legstar/) to generate parsers to read EBCDIC data, 
and use them in your [Cascading](http://cascading.io) application for scalable data processing.


Please note that while we give references to [Cascading Users Guide](http://docs.cascading.org/cascading/3.0/userguide/) 
for the APIs used to implement the ETL tasks, this tutorial is not intended to 
serve as an introduction to Cascading. For that, we recommend that you follow
the [Cascading for the Impatient](http://docs.cascading.org/impatient) tutorial.

Similarly, to get more information on Legstar, please visit [this page](http://www.legsem.com/legstar/).

If you have a question or run into any problems send an email to 
the [cascading-user-list](https://groups.google.com/forum/#!forum/cascading-user).

The tutorial contains extensive explanation on how to compile and run the code, but if you want to get started quickly,
please follow these instructions:

Build Instructions
==================

To build the sample app from the command line use:

    gradle clean fatjar


Execution Instructions for Local Mode
=====================================

To run the application from within directory:

    java -cp './build/libs/cascading-copybook-fat.jar' cascading.legstar.cobolcopybook.app.Main data/sample.dat

This command reads the EBCDIC encoded mainframe data file "sample.dat" present in the data folder, and prints its contents on the screen.

Verification Instructions
=========================

You should see output similar to what's shown below. This data was generated randomly for this tutorial, hence it contains alphanumeric characters.

    BdfoKey,Kcp01V05Sname,Kcp01V05BicIndclass,Kcp02V05TransfFromSortCode,Kcp07V05BalIdent_0,Kcp07V05Bal_0,Kcp07V05BalIdent_1,Kcp07V05Bal_1
    -6683146426114,%qU`!wOBsbE0'D |u*C3,-19679,0,-687,-0.04,-884,0.00
    -2385999825905,XSm<ZMGOlY)DjCo{1gq(,-25828,0,681,-0.03,405,-0.05
    5438010024578,W9U_>Ka0ryhsEr-OW8vh,-26619,0,-479,0.02,338,-0.03
    6691396553994,,-d`-YD4rE2h._m@HxR4,-44575,0,-108,0.00,324,0.04
    4865497093165,4Kg8t:s|vF-UbRdxD8wG,54268,0,143,0.04,-658,-0.05
    6276428590760,|06DBwkGK>2A#X=PB\c},55061,0,628,0.02,-553,-0.07
    -7679852317349,cV0yV#)p})K_1W\.6,Mf,16740,0,351,-0.04,-590,0.03
    1973377495564,DFCQ?nbcNMb%|3(H_[sa,-12642,0,280,-0.03,-420,-0.01
    -3045801617866,M$zw\dByPyTU+tFT.)C1,78127,0,175,0.03,835,-0.04
    -7038592107417,>!hL!ax}xY;tdu)r@36p,16818,0,673,-0.02,-680,-0.03
    1633360438639,1aN:p`O_L|=5S<Mb`!it,-27224,0,-806,-0.05,746,-0.05
    -8077733316035,:n#i,T]ou5R1jOTZ)zkB,-64427,0,550,-0.02,-940,-0.05
    -9367934855792,Uf0]xN)f(Sr]#'t>c9}-,-74473,0,425,-0.05,358,-0.05
    3644189969846,VgEpwC,yPr(#>uqXQ9LD,28880,0,-106,0.03,-503,-0.03
    -630123760551,eeuJ5%"5=)z>yWRP\^lA,26144,0,-840,-0.01,-708,-0.02
    6971792162880,Npu*,YGzv;(72a,uD<*O,-57225,0,-93,0.03,-171,-0.03
    -4491313438054,8{2u7EkIeua{_%:+P"n4,25961,0,-308,0.01,-310,-0.06
    -7809838685982,(K+!"p]KnaF,iR#n(Tj^,21580,0,364,-0.07,519,0.00
    662321675420,'V !+XpdZt,vKn=^":"E,59304,0,491,0.00,-238,-0.01
    8744669117912,=cL2n&szr7H8(0# <*V$,-93071,0,-785,-0.05,-893,0.04
    8402832501551,zRv8He"gE?`AU8#>9>w,-14999,0,-345,-0.07,777,0.00
    3815250249692,|Unf$>|RQqQtl;T[.4f2,-40813,0,-202,-0.06,580,-0.06


Execution Instructions for Hadoop
=================================

hadoop jar ./build/libs/cascading-copybook-fat.jar cascading.hadoop.legstar.cobol.hadoop.app.Main /tmp/ZOS.FCUSTDAT.RDW.bin output/custdat.csv

Verification Instructions
=========================

You should see output similar to what's shown below.

    15/02/12 16:08:49 INFO flow.Flow: [Cascading Cobol]  parallel execution is enabled: true
    15/02/12 16:08:49 INFO flow.Flow: [Cascading Cobol]  starting jobs: 1
    15/02/12 16:08:49 INFO flow.Flow: [Cascading Cobol]  allocating threads: 1
    15/02/12 16:08:49 INFO flow.FlowStep: [Cascading Cobol] starting step: (1/1) output/custdat.csv
    15/02/12 16:08:49 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
    15/02/12 16:08:50 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
    15/02/12 16:08:50 INFO mapred.FileInputFormat: Total input paths to process : 1
    15/02/12 16:08:50 INFO mapreduce.JobSubmitter: number of splits:2
    15/02/12 16:08:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1423764112257_0007
    15/02/12 16:08:51 INFO impl.YarnClientImpl: Submitted application application_1423764112257_0007
    15/02/12 16:08:51 INFO mapreduce.Job: The url to track the job: http://machine.local:8088/proxy/application_1423764112257_0007/
    15/02/12 16:08:51 INFO flow.FlowStep: [Cascading Cobol] submitted hadoop job: job_1423764112257_0007
    15/02/12 16:08:51 INFO flow.FlowStep: [Cascading Cobol] tracking url: http://machine.local:8088/proxy/application_1423764112257_0007/
    15/02/12 16:09:18 INFO util.Hadoop18TapUtil: deleting temp path output/custdat.csv/_temporary
    15/02/12 16:09:18 INFO state.AppStats: shutdown finalizing app status
    15/02/12 16:09:18 INFO state.AppStats: shutdown hook finished.
    15/02/12 16:09:19 INFO rest.DrivenDocumentService: https://trial.driven.io/driven/6628F19494964C95A4327543B402A298
    15/02/12 16:09:19 INFO rest.DrivenDocumentService: plugin version 1.2-eap-5
    15/02/12 16:09:19 INFO rest.DrivenDocumentService: stopped document service
    15/02/12 16:09:19 INFO util.Update: newer Cascading release available: 2.5.6
